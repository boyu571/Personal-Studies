{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL 이론.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjpcAnzKkwGyK14I/tN+Ju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boyu571/TIL/blob/master/DL_%EC%9D%B4%EB%A1%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH3LrO2vbqq-",
        "outputId": "bf17565f-e3ae-4a5d-c228-81ad20369d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "#python 버전 확인\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpODulIDbxWG",
        "outputId": "456ed24f-c5af-46a5-92c2-bcd4b8afe106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.8.2"
      ],
      "metadata": {
        "id": "_UZGR_KTb2ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorflow 2.0 장점\n",
        "# keras와 즉시 실행을 이용해서 쉬운 모델 작성 가능"
      ],
      "metadata": {
        "id": "KiTBPn23cSmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12시간 제한\n",
        "import torch"
      ],
      "metadata": {
        "id": "QvIXgcc4cihk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Layer"
      ],
      "metadata": {
        "id": "uzU62jxodbcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.FloatTensor([[1,2],\n",
        "                       [3,4],\n",
        "                       [5,6]])\n",
        "b = torch.FloatTensor([2,2])"
      ],
      "metadata": {
        "id": "aphtbRp9dXrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x, W, b):\n",
        "  y = torch.matmul(x,W) + b\n",
        "\n",
        "  return y"
      ],
      "metadata": {
        "id": "Va1Y9D1Hd51u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor(4,3)"
      ],
      "metadata": {
        "id": "D81eGHKJeFYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = linear(x, W, b)\n",
        "print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "ePN5TzlseRYM",
        "outputId": "d7023375-dc24-4fa7-d10b-0f0428f5294a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a0dc80b2a90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에는 nn(neural networks) 패키지가 있다. nn.Module을 상속받은 MyLinear라는 클래스를 정의. nn.Module을 상속받은 클래스는 보통 2개의 메서드 __init__과 forward 를 오버라이드합니다. __init__ 함수는 계층 내부에서 필요한 변수를 미리 선언하는 부분이며, 심지어 또 다른 계층(nn.Module을 상속받은 클래스의 객체)을 소유하도록 할 수도 있습니다. forward 함수는 계층을 통과하는데 필요한 계산을 수행하도록 구현하는 부분입니다."
      ],
      "metadata": {
        "id": "gvLiQo0yeoBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "DsOXoR5cegXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim = 3, output_dim = 2):\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.W = torch.FloatTensor(input_dim, output_dim)\n",
        "    self.b = torch.FloatTensor(output_dim)\n",
        "\n",
        "  # You should override 'forward' method to implement detail.\n",
        "  # The input arguments and outputs can be designed as you wish.\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # |x| = (batch_size, input_dim)\n",
        "    y = torch.matmul(x, self.W) + self.b\n",
        "    # |y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
        "    #     = (batch_size, output_dim)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "_Sg6NVHle4KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ],
      "metadata": {
        "id": "GpBcsUFmhcJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module을 상속받은 객체는 __call__함수와 forward가 맵핑되어 있어 forward를 직접 부를 필요가 없다. forward 함수를 따로 호출하지 않고, 객체명에 바로 괄호를 열어 tensor x를 인수로 넘겨주었다는 것.\n",
        "단, 내부에 학습할 수 있는 파라미터는 없는 것으로 인식."
      ],
      "metadata": {
        "id": "LChZD3t0iIn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in linear.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "id": "F1fsEKrjh5VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W와 b를 파이토칯에서 학습 가능하도록 인식할 수 있는 파라미터로 만들어주어야 함. torch.nn.Parameter 클래스를 활용."
      ],
      "metadata": {
        "id": "n1o42T6JjF9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim = 3, output_dim = 2):\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
        "    self.b = nn.Parameter(torch.FloatTensor(output_dim))\n",
        "\n",
        "  # You should override 'forward' method to implement detail.\n",
        "  # The input arguments and outputs can be designed as you wish.\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # |x| = (batch_size, input_dim)\n",
        "    y = torch.matmul(x, self.W) + self.b\n",
        "    # |y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
        "    #     = (batch_size, output_dim)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "yeDVFQ-Jiq-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ],
      "metadata": {
        "id": "ZIWK6qhqj-L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in linear.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h_gAj0ejpn2",
        "outputId": "1362da68-2461-495a-acdf-90f7a1cdc997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[9.5684e-33, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([9.5688e-33, 0.0000e+00], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사실 torch.nn에 미리 정의된 선형 계층을 호출하면 간단"
      ],
      "metadata": {
        "id": "Ijyf-IV-kHD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ],
      "metadata": {
        "id": "maYgnRLOkFc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in linear.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTfVosIWkTiK",
        "outputId": "3b58e361-1d34-417b-858c-fa995f0d9354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3576, -0.0927, -0.0186],\n",
            "        [-0.1692,  0.1588, -0.0810]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1458, -0.2834], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim = 3, output_dim = 2):\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # |x| = (batch_size, input_dim)\n",
        "    y = self.linear(x)\n",
        "    # |y| = (batch_size, output_dim)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "5x54KSb3kWlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUDA(Computed Unified Device Architecture)는 엔비디아 GPU에서 수행하는 병렬 연산을 프로그래밍 언어를 통해 구현할 수 있도록 하는 기술.\n",
        "CUDA 함수를 통해 GPU의 메모리 상에 텐서 생성 가능"
      ],
      "metadata": {
        "id": "t7xQO69gmJ6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.cuda.FloatTensor(2,2)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvHzg9e6lWK5",
        "outputId": "2a6cbbe2-ee0c-4413-ab95-9faaa650f085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor(2,2)\n",
        "x\n",
        "\n",
        "x = x.cuda()\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xGNbU1iojnG",
        "outputId": "3e281ce4-33bd-45d5-8315-0df4690b7a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-7.4171e-07,  0.0000e+00],\n",
              "        [ 0.0000e+00,  0.0000e+00]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.cuda(device=1) # If you don't have 2nd gpu, error will be occurred.\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "FOhSXbcMtS6h",
        "outputId": "03da28f3-02d0-4a93-abdf-57d3668f5074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-79c5422831de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# If you don't have 2nd gpu, error will be occurred.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서는 device 속성을 가지고 있어, 해당 텐서가 위치한 디바이스를 쉽게 파악할 수 있다."
      ],
      "metadata": {
        "id": "iSwJw_KIt4PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.cuda.FloatTensor(2, 2)\n",
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYv7PqmJtun1",
        "outputId": "3772d6d7-cfb0-473d-81b7-f924a9847fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " nn.Module의 하위 클래스 객체는 해당 속성을 갖고 있지 않다. 따라서 만약 모델이 어느 장치에 올라가있는지 알고 싶다면 다음과 같은 방법을 취할 수 있다."
      ],
      "metadata": {
        "id": "omddOEVHvL8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Linear(2, 2)\n",
        "next(layer.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-dXRaZCvCXB",
        "outputId": "6f393df9-2ca6-45a5-b9b5-d3e0fc7acd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BB9lq335vSkI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}